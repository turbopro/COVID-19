plot(1 : n.ahead, future_int[1, ], ylim = c(-8, 18),
type = "b", xlab = "month ahead", ylab = "rate",
cex.axis = 0.8, cex.lab = 0.9, lwd = 2)
for (i in 2:5)
{
lines(1 : n.ahead, future_int[i, ], type = "b", lty = i, lwd = 2, col = "blue")
}
ul_int <- 0 * (1 : n.ahead)
ll_int <- ul_int
for (k in 1 : n.ahead)
{
ul_int[k] = quantile(future_int[, k], 0.975)
ll_int[k] = quantile(future_int[, k], 0.025)
}
future_mean_int = apply(future_int, 2, mean)
#
plot(1 : n.ahead, ul_int , ylim = c(-5,15), type = "b", lwd = 2,
xlab = "month ahead", ylab = "rate", cex.axis = 0.8, cex.lab = 0.9)
lines(ll_int, type = "b", lwd = 2)
lines(future_mean_int)
#
pacf(bmw, main = "Sample PACF for daily BMW stock log returns")
data(bmw, package = "evir")
#
pacf(bmw, main = "Sample PACF for daily BMW stock log returns")
unlink('Documents/edu/Gen_R/UW-CFRM/CFRM502/week4/homework4_vwoolford_cache', recursive = TRUE)
d <- density(subsample, adjust = 1,na.rm= TRUE)plot(d)
x <- rnorm(100, 0, 2)
d <- density(x, adjust = 1,na.rm= TRUE)plot(d)
d <- density(x, adjust = 1,na.rm= TRUE)
plot(d)
d <- density(x, adjust = 2, na.rm= TRUE)
plot(d)
d <- density(x, adjust = 3, na.rm= TRUE)
plot(d)
knitr::opts_chunk$set(echo = TRUE)
library(xts)
dat <- read.table("HW4-Q4.txt", header = TRUE, sep = ",")
P_t <- ts(dat[, 2], start = c(1987, 1), end = c(2007, 12), frequency = 12)
#names(P_t) <- c("Oil")
#r_t <- diff(P_t)[-1]
r_t <- diff(P_t)
fitAR1 <- arima(r_t, order = c(1, 0, 0))
print(fitAR1)
fitMA2 <- arima(r_t, order = c(0, 0, 2))
print(fitMA2)
pr = predict(fitAR1, 12)
ts.plot(r_t, ylim = c(-10, 15), xlim = c(1987, 2010), type = 'l',
main = "Monthly Price Change Prediction for 2008")
lines(ts(pr$pred, star = 2008, frequency = 12), type='p', lty=1, pch='*')
lines(ts(pr$pred + 1.96 * pr$se, star = 2008, frequency = 12), type = 'l', lty = 2, col = 3)
lines(ts(pr$pred - 1.96 * pr$se, star = 2008, frequency = 12), type = 'l', lty = 2, col = 2)
legend("topleft", c("data", "predictions", "lower CL", "upper CL"), cex = 0.7,
box.lty = 1, pch = c(NA, "*", NA, NA), lty = c(1, NA, 2, 2), col = c(1, 1, 2, 3))
pr = predict(fitMA2, 12)
ts.plot(r_t, ylim = c(-10, 15), xlim = c(1987, 2010), type = 'l',
main = "Monthly Price Change Prediction for 2008")
lines(ts(pr$pred, star = 2008, frequency = 12), type='p', lty=1, pch='*')
lines(ts(pr$pred + 1.96 * pr$se, star = 2008, frequency = 12), type = 'l', lty = 2, col = 3)
lines(ts(pr$pred - 1.96 * pr$se, star = 2008, frequency = 12), type = 'l', lty = 2, col = 2)
legend("topleft", c("data", "predictions", "lower CL", "upper CL"), cex = 0.7,
box.lty = 1, pch = c(NA, "*", NA, NA), lty = c(1, NA, 2, 2), col = c(1, 1, 2, 3))
RMSE <- function(h, t_0, t_pred, rth, rth_hat) {
# difference between T and t0
t_diff <- ((as.yearmon(strptime(t_pred, format = "%d.%m.%Y")) -
as.yearmon(strptime(t_0, format = "%d.%m.%Y"))) * 12) - h + 1
# t_diff <- ((as.yearmon(strptime("31.01.2018", format = "%d.%m.%Y")) -
#            as.yearmon(strptime("01.12.2007", format = "%d.%m.%Y"))) * 12) - h + 1
# sum of square errors
SSE <- (rth - rth_hat)**2
return(sqrt(SSE / t_diff))
}
h <- 1
t_0 <- "01.12.2007"
t_pred <- "31.01.2018"
rth <-
(as.yearmon(strptime(t_pred, format = "%d.%m.%Y")) -
as.yearmon(strptime(t_0, format = "%d.%m.%Y"))) * 12
(as.yearmon(strptime("31.01.2018", format = "%d.%m.%Y")) -
as.yearmon(strptime("01.12.2007", format = "%d.%m.%Y"))) * 12
knitr::opts_chunk$set(echo = TRUE)
library(quantmod)
HS <- getSymbols("HSN1FNSA", src = "FRED", auto.assign = FALSE)
HS <- ts(as.numeric(HS), start = c(1963, 1), end = c(2018, 11), frequency = 12)
dHS <- diff(HS, lag = 1)
ts.plot(dHS)
acf(as.numeric(dHS), main = ("Sample ACF of Monthly Change in Houses Sold"))
# check for unit roots
library(tseries)
adf.test(dHS)
pp.test(dHS)
kpss.test(dHS)
# seasonalACF function
seasonalACF = function(ts, slag, name){
par(mfrow=c(2,2),mar=c(2,3,4,4))
acf(as.numeric(ts), main=paste("sample ACF of ", name))
acf(as.numeric(diff(ts)), main="first difference")
acf(as.numeric(diff(ts,slag)), main="seasonal difference")
acf(as.numeric(diff(diff(ts),slag)), main="regular+seasonal differene")
}
seasonalACF(HS, 1, "Housing Starts")
HS_airline <- arima(as.numeric(HS), order = c(0, 1, 1),
seasonal = list(order = c(0, 1, 1), period = 12))
HS_airline
par(mar = c(2, 3, 4, 4))
tsdiag(HS_airline, gof = 12)
tsdiag_vol = function(model, lag, fitdf, span=0.5){
par(mfrow=c(1,2));par(mar=c(3,3,3,3))
plot(resid(model)**2, type="l", col=1,
main = expression(residual^2))
smoother = loess((resid(model)**2) ~ seq(1,length(resid(model))),
span=span)
lines(seq(1,length(resid(model))),fitted(smoother),col=2)
acf((resid(model)**2), main=expression("sample ACF of "~ residual^2))
Box.test(resid(model)**2, lag = lag, type = "Ljung-Box", fitdf = fitdf)
}
tsdiag_norm = function(model){
qqnorm(resid(model), datax = FALSE,
xlab = "normal quantile",
ylab = "sample quantile of residuals",
main = "normal probability plot for residuals")
qqline(resid(model), datax=FALSE, col = 2)
shapiro.test(resid(model))
}
tsdiag_vol(HS_airline, lag=12, fitdf=2)
par(mfrow = c(1, 1))
tsdiag_norm(HS_airline)
pred_HS <- predict(HS_airline, 12)
ts.plot(HS, ylim = c(10, 130), xlim = c(1963, 2025), type = "l",
main = "Monthly Housing Starts: 12-month Forecast")
lines(ts(pred_HS$pred, start = c(2018, 12), frequency = 12), type = 'p', lty = 1, pch = '*', col = "blue")
lines(ts(pred_HS$pred + 1.96 * pred_HS$se, start = c(2018, 12), frequency = 12), type = 'l', lty = 2, col = 3)
lines(ts(pred_HS$pred - 1.96 * pred_HS$se, start = c(2018, 12), frequency = 12), type = 'l', lty = 2, col = 2)
legend("topleft", c("data", "predictions", "lower CL", "upper CL"), cex = 0.8,
box.lty = 1, pch = c(NA, "*", NA, NA), lty = c(1, NA, 2, 2), col = c(1, 4, 2, 3))
library(forecast)
HS_SARIMA <- auto.arima(HS, ic = "bic",
max.p = 20, max.q = 20, max.d = 3,
max.P = 20, max.Q = 20, max.D = 3)
HS_SARIMA
par(mar = c(2, 3, 4, 4))
tsdiag(HS_SARIMA, gof = 12)
tsdiag_vol(HS_SARIMA, lag = 12, fitdf = 2)
par(mfrow = c(1, 1))
tsdiag_norm(HS_SARIMA)
pred_HS_SARIMA <- predict(HS_SARIMA, 12)
ts.plot(HS, ylim = c(10, 130), xlim = c(1963, 2025), type = "l",
main = "Monthly Housing Starts: 12-month Forecast")
lines(ts(pred_HS_SARIMA$pred, start = c(2018, 12), frequency = 12), type = 'p', lty = 1, pch = '*', col = "blue")
lines(ts(pred_HS_SARIMA$pred + 1.96 * pred_HS_SARIMA$se, start = c(2018, 12), frequency = 12),
type = 'l', lty = 2, col = 3)
lines(ts(pred_HS_SARIMA$pred - 1.96 * pred_HS_SARIMA$se, start = c(2018, 12), frequency = 12),
type = 'l', lty = 2, col = 2)
legend("topleft", c("data", "predictions", "lower CL", "upper CL"), cex = 0.8,
box.lty = 1, pch = c(NA, "*", NA, NA), lty = c(1, NA, 2, 2), col = c(1, 4, 2, 3))
# For h = 1
h <- 1
t0 <- 0
# calclate number of periods between out-of-sample start period, Jan 2008, and end period, Jan 2018
t_diff <- round((as.yearmon(strptime("01-11-2018", format = "%d-%m-%Y")) -
as.yearmon(strptime("01-01-2000", format = "%d-%m-%Y"))) * 12)
# store sample time series values in a numeric vector
rt_train <- as.vector(window(HS, end = c(2000, 1)))
test0 <- as.vector(HS)
test1 <- as.numeric(HS)
test0 - test1
HS_SARIMA0 <- auto.arima(as.numeric(HS), ic = "bic",
max.p = 20, max.q = 20, max.d = 3,
max.P = 20, max.Q = 20, max.D = 3)
HS_SARIMA0
HS_SARIMA
HS_SARIMA0
HS_SARIMA0 <- auto.arima(as.vector(HS), ic = "bic",
max.p = 20, max.q = 20, max.d = 3,
max.P = 20, max.Q = 20, max.D = 3)
HS_SARIMA0
HS_SARIMA
HS_airline0 <- arima(as.numeric(HS), order = c(0, 1, 1),
seasonal = list(order = c(0, 1, 1), period = 12))
HS_airline0
HS_airline0 <- arima(HS, order = c(0, 1, 1),
seasonal = list(order = c(0, 1, 1), period = 12))
HS_airline0
# store sample time series values in a numeric vector
rt_train <- as.vector(window(HS, end = c(2000, 1)))
# fit Airline and SARIMA models
fitAL_h <- arima(rt_train, order = c(0, 1, 1),
seasonal = list(order = c(0, 1, 1), period = 12))
fitAL_h
fitSAR_h <- auto.arima(HS, ic = "bic",
max.p = 20, max.q = 20, max.d = 3,
max.P = 20, max.Q = 20, max.D = 3)
fitSAR_h <- auto.arima(rt_train, ic = "bic",
max.p = 20, max.q = 20, max.d = 3,
max.P = 20, max.Q = 20, max.D = 3)
# get rhat_h prediction values for out-of-sample periods, Feb 2000 to Oct 2018
# Oct 2018 is the 'T-h' upper limit for the Sum in the formula
rhat_h_AL <- as.vector(predict(fitAL_h, t_diff)$pred)
rhat_h_SAR <- as.vector(predict(fitSAR_h, t_diff)$pred)
# get the r(t+h) out-of-sample values from Feb 2000 to Oct 2018
rt_h <- as.vector(window(HS, start = c(2000, 2), end = c(2018, 10)))
# calclate number of periods between out-of-sample start period, Feb 2000, and end period, Nov 2018
t_diff <- round((as.yearmon(strptime("01-11-2018", format = "%d-%m-%Y")) -
as.yearmon(strptime("01-02-2000", format = "%d-%m-%Y"))) * 12)
# store sample time series values in a numeric vector
rt_train <- as.vector(window(HS, end = c(2000, 1)))
# fit Airline and SARIMA models
fitAL_h <- arima(rt_train, order = c(0, 1, 1),
seasonal = list(order = c(0, 1, 1), period = 12))
fitSAR_h <- auto.arima(rt_train, ic = "bic",
max.p = 20, max.q = 20, max.d = 3,
max.P = 20, max.Q = 20, max.D = 3)
# get rhat_h prediction values for out-of-sample periods, Feb 2000 to Oct 2018
# Oct 2018 is the 'T-h' upper limit for the Sum in the formula
rhat_h_AL <- as.vector(predict(fitAL_h, t_diff)$pred)
rhat_h_SAR <- as.vector(predict(fitSAR_h, t_diff)$pred)
# get the r(t+h) out-of-sample values from Feb 2000 to Oct 2018
rt_h <- as.vector(window(HS, start = c(2000, 2), end = c(2018, 10)))
# calculate the RMSE(h)
RMSE_1_AL <- RMSE_h(h, t0, t_diff, rt_h, rhat_h_AL)
# function to calculate RMSE(h)
RMSE_h <- function(h, t_0, t_h, rt_h, rhat_h) {
# Arg       Desc                      Type/Format
# -----------------------------------------------
# h:        step-ahead                integer
# t_0:      t0                        integer
# t_h:      T                         integer
# rt_h:     Out-of-Sample ts values   numeric vector
# rhat_h:   Prediction ts values      numeric vector
return(sqrt(sum((rt_h - rhat_h)**2) / (t_h - h - t_0 + 1)))
}
# calculate the RMSE(h)
RMSE_1_AL <- RMSE_h(h, t0, t_diff, rt_h, rhat_h_AL)
RMSE_1_SAR <- RMSE_h(h, t0, t_diff, rt_h, rhat_h_SAR)
#####
# For h = 2
h <- 2
t0 <- 1
# calclate number of periods between out-of-sample start period, Feb 2008, and end period, Dec 2017
t_diff <- round((as.yearmon(strptime("01-10-2018", format = "%d-%m-%Y")) -
as.yearmon(strptime("01-03-2000", format = "%d-%m-%Y"))) * 12)
# store sample time series values in a numeric vector
rt_train <- as.vector(window(HS, end = c(2000, 2)))
# fit Airline and SARIMA models
fitAL_h <- arima(rt_train, order = c(0, 1, 1),
seasonal = list(order = c(0, 1, 1), period = 12))
fitSAR_h <- auto.arima(rt_train, ic = "bic",
max.p = 20, max.q = 20, max.d = 3,
max.P = 20, max.Q = 20, max.D = 3)
# get rhat_h prediction values for out-of-sample periods, Mar 2000 to Sep 2018
# Sep 2018 is the 'T-h' upper limit for the Sum in the formula
rhat_h_AL <- as.vector(predict(fitAL_h, t_diff)$pred)
rhat_h_SAR <- as.vector(predict(fitSAR_h, t_diff)$pred)
# get the r(t+h) out-of-sample values from Mar 2000 to Sep 2018
rt_h <- as.vector(window(HS, start = c(2000, 3), end = c(2018, 9)))
# calculate the RMSE(h)
RMSE_1_AL <- RMSE_h(h, t0, t_diff, rt_h, rhat_h_AL)
RMSE_1_SAR <- RMSE_h(h, t0, t_diff, rt_h, rhat_h_SAR)
# For h = 1
h <- 1
t0 <- 0
# calclate number of periods between out-of-sample start period, Feb 2000, and end period, Nov 2018
t_diff <- round((as.yearmon(strptime("01-11-2018", format = "%d-%m-%Y")) -
as.yearmon(strptime("01-02-2000", format = "%d-%m-%Y"))) * 12)
# store sample time series values in a numeric vector
rt_train <- as.vector(window(HS, end = c(2000, 1)))
# fit Airline and SARIMA models
fitAL_h <- arima(rt_train, order = c(0, 1, 1),
seasonal = list(order = c(0, 1, 1), period = 12))
fitSAR_h <- auto.arima(rt_train, ic = "bic",
max.p = 20, max.q = 20, max.d = 3,
max.P = 20, max.Q = 20, max.D = 3)
# get rhat_h prediction values for out-of-sample periods, Feb 2000 to Oct 2018
# Oct 2018 is the 'T-h' upper limit for the Sum in the formula
rhat_h_AL <- as.vector(predict(fitAL_h, t_diff)$pred)
rhat_h_SAR <- as.vector(predict(fitSAR_h, t_diff)$pred)
# get the r(t+h) out-of-sample values from Feb 2000 to Oct 2018
rt_h <- as.vector(window(HS, start = c(2000, 2), end = c(2018, 10)))
# calculate the RMSE(h)
RMSE_1_AL <- RMSE_h(h, t0, t_diff, rt_h, rhat_h_AL)
RMSE_1_SAR <- RMSE_h(h, t0, t_diff, rt_h, rhat_h_SAR)
#####
# For h = 2
h <- 2
t0 <- 1
# calclate number of periods between out-of-sample start period, Feb 2008, and end period, Dec 2017
t_diff <- round((as.yearmon(strptime("01-10-2018", format = "%d-%m-%Y")) -
as.yearmon(strptime("01-03-2000", format = "%d-%m-%Y"))) * 12)
# store sample time series values in a numeric vector
rt_train <- as.vector(window(HS, end = c(2000, 2)))
# fit Airline and SARIMA models
fitAL_h <- arima(rt_train, order = c(0, 1, 1),
seasonal = list(order = c(0, 1, 1), period = 12))
fitSAR_h <- auto.arima(rt_train, ic = "bic",
max.p = 20, max.q = 20, max.d = 3,
max.P = 20, max.Q = 20, max.D = 3)
# get rhat_h prediction values for out-of-sample periods, Mar 2000 to Sep 2018
# Sep 2018 is the 'T-h' upper limit for the Sum in the formula
rhat_h_AL <- as.vector(predict(fitAL_h, t_diff)$pred)
rhat_h_SAR <- as.vector(predict(fitSAR_h, t_diff)$pred)
# get the r(t+h) out-of-sample values from Mar 2000 to Sep 2018
rt_h <- as.vector(window(HS, start = c(2000, 3), end = c(2018, 9)))
# calculate the RMSE(h)
RMSE_2_AL <- RMSE_h(h, t0, t_diff, rt_h, rhat_h_AL)
RMSE_2_SAR <- RMSE_h(h, t0, t_diff, rt_h, rhat_h_SAR)
#####
# For h = 12
h <- 12
t0 <- 11
# calclate number of periods between out-of-sample start period, Feb 2001, and end period, Nov 2017
t_diff <- round((as.yearmon(strptime("01-11-2017", format = "%d-%m-%Y")) -
as.yearmon(strptime("01-02-2001", format = "%d-%m-%Y"))) * 12)
# store sample time series values in a numeric vector
rt_train <- as.vector(window(HS, end = c(2001, 1)))
# fit Airline and SARIMA models
fitAL_h <- arima(rt_train, order = c(0, 1, 1),
seasonal = list(order = c(0, 1, 1), period = 12))
fitSAR_h <- auto.arima(rt_train, ic = "bic",
max.p = 20, max.q = 20, max.d = 3,
max.P = 20, max.Q = 20, max.D = 3)
# get rhat_h prediction values for out-of-sample periods, Feb 2001 to Nov 2017
# Nov 2017 is the 'T-h' upper limit for the Sum in the formula
rhat_3_AL <- as.vector(predict(fitAL_h, t_diff)$pred)
rhat_3_SAR <- as.vector(predict(fitSAR_h, t_diff)$pred)
rm(rhat_3_AL)
rm(rhat_3_SAR)
# get rhat_h prediction values for out-of-sample periods, Feb 2001 to Nov 2017
# Nov 2017 is the 'T-h' upper limit for the Sum in the formula
rhat_h_AL <- as.vector(predict(fitAL_h, t_diff)$pred)
rhat_h_SAR <- as.vector(predict(fitSAR_h, t_diff)$pred)
# get the r(t+h) out-of-sample values from Feb 2001 to Nov 2017
rt_h <- as.vector(window(HS, start = c(2001, 2), end = c(2017, 11)))
# calclate number of periods between out-of-sample start period, Feb 2001, and end period, Dec 2017
t_diff <- round((as.yearmon(strptime("01-12-2017", format = "%d-%m-%Y")) -
as.yearmon(strptime("01-02-2001", format = "%d-%m-%Y"))) * 12)
# store sample time series values in a numeric vector
rt_train <- as.vector(window(HS, end = c(2001, 1)))
# fit Airline and SARIMA models
fitAL_h <- arima(rt_train, order = c(0, 1, 1),
seasonal = list(order = c(0, 1, 1), period = 12))
fitSAR_h <- auto.arima(rt_train, ic = "bic",
max.p = 20, max.q = 20, max.d = 3,
max.P = 20, max.Q = 20, max.D = 3)
# get rhat_h prediction values for out-of-sample periods, Feb 2001 to Nov 2017
# Nov 2017 is the 'T-h' upper limit for the Sum in the formula
rhat_h_AL <- as.vector(predict(fitAL_h, t_diff)$pred)
rhat_h_SAR <- as.vector(predict(fitSAR_h, t_diff)$pred)
# get the r(t+h) out-of-sample values from Feb 2001 to Nov 2017
rt_h <- as.vector(window(HS, start = c(2001, 2), end = c(2017, 11)))
# calculate the RMSE(h)
RMSE_3_AL <- RMSE_h(h, t0, t_diff, rt_h, rhat_h_AL)
RMSE_3_SAR <- RMSE_h(h, t0, t_diff, rt_h, rhat_h_SAR)
# store results in a tibble
library(tibble)
RMSE_df <- tibble(Model = c("AR1", "MA2"))
add_column(RMSE_df, RMSE_1 = c(RMSE_1_AL, RMSE_1_SAR), RMSE_2 = c(RMSE_2_AL, RMSE_2_SAR),
RMSE_3 = c(RMSE_3_AL, RMSE_3_SAR))
# effective interest rate# => 1 + r_e = (1 + r/n)^12
r_e <- function(r, n) { ( 1 + r/n)**n }
# effective interest rate# => r_e = (1 + r/n)^n - 1
r_e <- function(r, n) { ( 1 + r/n)**n - 1 }
r_0575 <- r_e(0.0575, 12)
cci
cci <- function(P, r, t) { P * exp(r * t) }
P <- 3585; r <- 0.0615; t <- 2.5
A_0615 <- cci(P, r, t)
# The effective simple interest rate => e^(r) = 1 + r_e => r_e = e^(r) - 1
exp(r) - 1
library(xts)
library(tidyverse)
dat_confirmed <- read_csv("./time_series_19-covid-Confirmed.csv")
setwd("~/Documents/utils/COVID-19/csse_covid_19_data/csse_covid_19_time_series")
dat_confirmed <- read_csv("./time_series_19-covid-Confirmed.csv")
library(tidyr)
library(magrittr)
# load data
dat_dates <- dat_confirmed %>% gather(Day, Cases, -c('Province/State', 'Country/Region', 'Lat', 'Long'))
# convert Day from 'chr' to 'Date'
dat_dates %<>%
mutate(Day = as.Date(Day, format = "%m/%d/%y")) %>%
select(c(Day, Cases)) %>%
group_by(Day) %>%
summarise(CaseCount = sum(Cases))
dat_xts <- xts(dat_dates$CaseCount, order.by = dat_dates$Day)
names(dat_xts) <- "Count"
plot(dat_xts, type = "h", legend.loc = 'top',
legend = "Test text",
main = "Total Confirmed", col = "blue")
ts.plot(dat_xts, main = "Test")
legend("top", legend = c("Test"))
ts.plot(dat_xts, main = "Test", type = "h")
dat_xts[1]
dat_xts$Count
dat_xts$Count$Count
dat_xts$Count[1]
dat_xts$Count[51]
class(dat_xts$Count[51])
as.numeric(dat_xts$Count[51])
plot(dat_xts, type = "h",
main = expression(paste("Total Confirmed Cases:", as.numeric(dat_xts$Count[51]))),
col = "blue")
plot(dat_xts, type = "h",
main = expression("Total Confirmed Cases:", as.numeric(dat_xts$Count[51])),
col = "blue")
plot(dat_xts, type = "h",
main = paste("Total Confirmed Cases:", as.numeric(dat_xts$Count[51])),
col = "blue")
plot(dat_xts, type = "h",
main = paste("Total Confirmed Cases:", as.numeric(dat_xts$Count[nrow(dat_xts)])),
col = "blue")
plot(dat_xts, type = "h",
main = paste("Total Confirmed Cases:", as.numeric(dat_xts$Count[nrow(dat_xts)]),
"\nAs of:"),
col = "blue")
time(dat_xts)[51]
curr_len <- nrow(dat_xts)
plot(dat_xts, type = "h",
main = paste("Total Confirmed Cases:", as.numeric(dat_xts$Count[curr_len]),
"\nAs of:", time(dat_xts[curr_len])),
col = "blue")
plot(dat_xts, type = "h",
main = paste("Total Confirmed Cases:", as.numeric(dat_xts$Count[curr_len]),
"\nAs of:", time(dat_xts[curr_len])),
col = "red")
plot(dat_xts, type = "h",
main = paste("Total Confirmed Cases:", as.numeric(dat_xts$Count[curr_len]),
"\nAs of:", time(dat_xts[curr_len])),
col = "green")
plot(dat_xts, type = "h",
main = paste("Worlwide Confirmed Cases:", as.numeric(dat_xts$Count[curr_len]),
"\nAs of:", time(dat_xts[curr_len])),
col = "green")
plot(dat_xts, type = "h",
main = paste("Worlwide Confirmed Cases:", as.numeric(dat_xts$Count[curr_len]),
"\nAs of:", time(dat_xts[curr_len])),
col = "green", grid.col = "lightgrey")
ts.plot(dat_xts, main = "Test", type = "h")
plot(dat_xts, type = "h",
main = paste("Worlwide Confirmed Cases:", as.numeric(dat_xts$Count[curr_len]),
"\nAs of:", time(dat_xts[curr_len])),
col = "green", grid.col = "lightgrey", grid.ticks.lty = "dotted")
plot(dat_xts, type = "h",
main = paste("Worlwide Confirmed Cases:", as.numeric(dat_xts$Count[curr_len]),
"\nAs of:", time(dat_xts[curr_len])),
col = "lightblue", grid.col = "lightgrey", grid.ticks.lty = "dotted")
plot(dat_xts, type = "h",
main = paste("Worlwide Confirmed Cases:", as.numeric(dat_xts$Count[curr_len]),
"\nAs of:", time(dat_xts[curr_len])),
col = "darkblue", grid.col = "lightgrey", grid.ticks.lty = "dotted")
plot(dat_xts, type = "h",
main = paste("Worlwide Confirmed Cases:", as.numeric(dat_xts$Count[curr_len]),
"\nAs of:", time(dat_xts[curr_len])),
col = "blue", grid.col = "lightgrey", grid.ticks.lty = "dotted")
plot(dat_xts, type = "h",
main = paste("Worlwide Confirmed Cases:", as.numeric(dat_xts$Count[curr_len]),
"\nAs of:", time(dat_xts[curr_len])),
col = "darkgreen", grid.col = "lightgrey", grid.ticks.lty = "dotted")
plot(dat_xts, type = "s",
main = paste("Worlwide Confirmed Cases:", as.numeric(dat_xts$Count[curr_len]),
"\nAs of:", time(dat_xts[curr_len])),
col = "darkgreen", grid.col = "lightgrey", grid.ticks.lty = "dotted")
plot(dat_xts, type = "S",
main = paste("Worlwide Confirmed Cases:", as.numeric(dat_xts$Count[curr_len]),
"\nAs of:", time(dat_xts[curr_len])),
col = "darkgreen", grid.col = "lightgrey", grid.ticks.lty = "dotted")
dat_xts
dat_dates
dat_confirmed <- read_csv("./time_series_19-covid-Confirmed.csv")
library(tidyr)
library(magrittr)
# load data
dat_dates <- dat_confirmed %>% gather(Day, Cases, -c('Province/State', 'Country/Region', 'Lat', 'Long'))
dat_dates
dat_dates["Country/Region" = "US", ]
dat_dates["Country/Region" = "US"]
dat_dates[,"Country/Region" = "US"]
dat_dates[,"Country/Region" == "US"]
dat_dates[,"Country/Region" == "France"]
### US
US_dat <- dat_dates %>%
group_by('Country/Region') %>%
filter('Country/Region' == "US")
### US
US_dat <- dat_dates %>%
group_by('Country/Region') %>%
filter(., 'Country/Region' == "US")
CR_dat <- dat_dates %>%
group_by('Country/Region')
CR_dat
### US
US_dat <- dat_dates %>%
group_by('Country/Region') %>%
filter(., 'Country/Region' == "Canada")
### US
US_dat <- dat_dates %>%
filter('Country/Region' == "Canada")
### US
US_dat <- dat_dates %>%
filter(Country/Region == "Canada")
day_dat <- dat_dates %>%
filter(Day == "1/22/20")
day_dat
### US
US_dat <- dat_dates %>%
filter("Country/Region" == "Canada")
dat_dates
filter(dat_dates, "Country/Region" == "Canada")
filter(dat_dates, `Country/Region` == "Canada")
### US
US_dat <- dat_dates %>%
filter(`Country/Region` == "US")
US_dat
